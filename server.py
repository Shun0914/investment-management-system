import subprocess
import json
import os
import uuid
import csv
from datetime import datetime
from mcp.server.fastmcp import FastMCP
from mcp.server.fastmcp import Context
from mcp.server.fastmcp.prompts import base
from dataclasses import dataclass
from contextlib import asynccontextmanager
from collections.abc import AsyncIterator

# Base directory settings
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_DIR = os.path.join(BASE_DIR, "db")
INVESTMENT_DIR = os.path.join(BASE_DIR, "investment_data")
PROJECTS_FILE = os.path.join(DB_DIR, "projects.json")
SERVERS_FILE = os.path.join(DB_DIR, "servers.json")
TASKS_FILE = os.path.join(DB_DIR, "tasks.json")
ACTIVE_CONTEXT_FILE = os.path.join(DB_DIR, "active_context.json")
ERRORS_FILE = os.path.join(DB_DIR, "errors.json")

# æŠ•è³‡ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®åˆæœŸåŒ–
INVESTMENT_SUBDIRS = ["raw_data", "dashboards", "philosophy", "processed"]
for subdir in INVESTMENT_SUBDIRS:
    os.makedirs(os.path.join(INVESTMENT_DIR, subdir), exist_ok=True)

# ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œç”¨å®‰å…¨çµåˆé–¢æ•°
def safe_join(*paths) -> str:
    full_path = os.path.abspath(os.path.join(BASE_DIR, *paths))
    if not full_path.startswith(BASE_DIR):
        raise ValueError("Invalid path access detected.")
    return full_path

# JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿æ›¸ãé–¢æ•°
def load_json(path: str, default):
    full_path = safe_join(path)
    if not os.path.exists(full_path):
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        with open(full_path, "w", encoding="utf-8") as f:
            json.dump(default, f, indent=2, ensure_ascii=False)
        return default
    with open(full_path, "r", encoding="utf-8") as f:
        return json.load(f)

def save_json(path: str, data):
    full_path = safe_join(path)
    os.makedirs(os.path.dirname(full_path), exist_ok=True)
    with open(full_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

# ã‚¨ãƒ©ãƒ¼è¨˜éŒ²é–¢æ•°ï¼ˆå±¥æ­´è¿½åŠ å¯¾å¿œç‰ˆï¼‰
def record_error(error_message: str) -> None:
    errors = load_json("db/errors.json", [])
    error_data = {
        "error_message": error_message,
        "timestamp": datetime.utcnow().isoformat()
    }
    errors.append(error_data)
    save_json("db/errors.json", errors)

# ä»®ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
@dataclass
class AppContext:
    db: dict[str, str]

@asynccontextmanager
async def app_lifespan(server) -> AsyncIterator[AppContext]:
    db = {}
    print("[MCP Server] èµ·å‹•ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    try:
        yield AppContext(db=db)
    finally:
        db.clear()
        print("[MCP Server] çµ‚äº†ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")

mcp = FastMCP(
    "Investment Management System",
    lifespan=app_lifespan
)

# --------------- Tools ---------------- #
@mcp.tool()
def instruction_policy() -> str:
    """
    Claudeãªã©ã®AIãŒå¿…ãšå¾“ã†ã¹ãé–‹ç™ºãƒ«ãƒ¼ãƒ«ãƒ»æ“ä½œãƒãƒªã‚·ãƒ¼ã€‚
    ã“ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ã€äº‹å‰ã«ãƒãƒªã‚·ãƒ¼ã‚’èª­ã¿è¾¼ã‚€ã“ã¨ã€‚
    """

    return """
==============================
MCPã‚µãƒ¼ãƒãƒ¼æ“ä½œãƒãƒªã‚·ãƒ¼
==============================

ã€é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã®åŸå‰‡ã€‘
1. ãƒ¬ãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³ã®ç¶­æŒã‚’æœ€å„ªå…ˆã¨ã™ã‚‹
   - docs/ - å…¨ã¦ã®è¨­è¨ˆæ›¸ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
   - reports/ - é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ
   - logs/error_logs/ - ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
2. å„æ“ä½œå‰ã«é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèªã™ã‚‹
3. æ“ä½œå¾Œã¯å¿…ãšçµæœã‚’ç¢ºèªã—ã€é©åˆ‡ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ/æ›´æ–°ã™ã‚‹

ã€ä½¿ç”¨å¯èƒ½ãªToolã€‘
- read_code - ã‚³ãƒ¼ãƒ‰å†…å®¹ã®èª­ã¿å–ã‚Š
- create_code - æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
- update_code - æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£
- delete_code - ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
- move_code - ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•
- list_files_in_directory - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹ç¢ºèª
- create_directory - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
- check_code - ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆé™çš„è§£æï¼‰

ã€å„Toolã®ä½¿ç”¨ãƒ«ãƒ¼ãƒ«ã€‘

â–  update_code
- æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦ã®ã¿ä½¿ç”¨å¯èƒ½
- éƒ¨åˆ†çš„ãªä¿®æ­£ã«é™å®šï¼ˆå…¨ä½“æ›¸ãæ›ãˆã¯ç¦æ­¢ï¼‰
- å¤‰æ›´å†…å®¹ã‚’æ˜ç¢ºã«èª¬æ˜ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 

â–  create_code
- æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆæ™‚ã®ã¿ä½¿ç”¨
- ãƒ•ã‚¡ã‚¤ãƒ«å†’é ­ã«ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›®çš„ã¨ä½œæˆæ—¥ã‚’è¨˜è¼‰
- åŒåãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’äº‹å‰ã«ç¢ºèªã™ã‚‹ã“ã¨

â–  delete_code
- å‰Šé™¤å‰ã«ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèª
- å‰Šé™¤ç†ç”±ã‚’æ˜è¨˜ã—ãŸã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä½œæˆ
- å‰Šé™¤å¾Œã®å½±éŸ¿ç¯„å›²ã‚’ç¢ºèª

â–  check_code
- ã‚³ãƒ¼ãƒ‰å¤‰æ›´å¾Œã«ä½¿ç”¨ã—ã€åŸºæœ¬çš„ãªå•é¡Œã‚’äº‹å‰ã«ç™ºè¦‹
- ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚„æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’ä¸­å¿ƒã«ãƒã‚§ãƒƒã‚¯
- ã‚¨ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã¯å³æ™‚ä¿®æ­£

ã€ãƒ¬ãƒãƒ¼ãƒˆç®¡ç†ãƒ«ãƒ¼ãƒ«ã€‘

â–  ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
- ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«å³åº§ã« logs/error_logs/ ã«ä½œæˆ
- å‘½åè¦å‰‡: ERROR_YYYYMMDDNNN.md
- å†…å®¹: ã‚¨ãƒ©ãƒ¼å†…å®¹ã€ç™ºç”ŸçŠ¶æ³ã€åŸå› åˆ†æã€ä¿®æ­£å†…å®¹
- error_logs_index.md ã‚’å¿…ãšæ›´æ–°

â–  é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ
- æŒ‡ç¤ºãŒã‚ã£ãŸå ´åˆã« reports/ ã«ä½œæˆ
- å‘½åè¦å‰‡: progress_YYYYMMDDNNN.md
- å†…å®¹: é€²æ—çŠ¶æ³ã€å®Œäº†ã‚¿ã‚¹ã‚¯ã€æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
- reports_index.md ã‚’å¿…ãšæ›´æ–°

ã€ã‚¹ãƒ¬ãƒƒãƒ‰é‹ç”¨ãƒ«ãƒ¼ãƒ«ã€‘
- 1ã‚¿ãƒ¼ãƒ³ã«1ã¤ã®æ“ä½œã¾ã§ï¼ˆè¤‡æ•°æ“ä½œã¯ç¦æ­¢ï¼‰
- ã‚¹ãƒ¬ãƒƒãƒ‰ãƒªãƒŸãƒƒãƒˆæ¥è¿‘æ™‚ã¯docs/ã«ç¾çŠ¶ã‚’ã¾ã¨ã‚ã‚‹
- æ–°ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹æ™‚ã¯æ—¢å­˜ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€

ã€ç¦æ­¢äº‹é …ã€‘
- ãƒ¬ãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³ã®ç„¡è¦–ãƒ»çœç•¥
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°å¿˜ã‚Œ
- ä¿®æ­£å†…å®¹ã®ä¸æ˜ç¢ºãªè¨˜è¿°
- ç‹¬è‡ªåˆ¤æ–­ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã®å¤‰æ›´
- ä¸€åº¦ã®æ›´æ–°ã§å¤§è¦æ¨¡ãªå¤‰æ›´ã‚’è¡Œã†ã“ã¨

==============================
"""

@mcp.tool()
def create_directory(path: str) -> str:
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚
    """
    try:
        full_path = safe_join(path)
        os.makedirs(full_path, exist_ok=True)
        return f"Directory '{path}' created successfully."
    except Exception as e:
        record_error(str(e))
        return f"Failed to create directory '{path}': {str(e)}"

@mcp.tool()
def read_code(file_path: str) -> str:
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿å–ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚
    ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™ã€‚
    """
    try:
        full_path = safe_join(file_path)
        if not os.path.exists(full_path):
            raise FileNotFoundError(f"File '{file_path}' not found.")
        with open(full_path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception as e:
        record_error(str(e))
        return str(e)

@mcp.tool()
def update_code(file_path: str, new_content: str = None, new_str: str = None) -> str:
    """
    æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’æ›´æ–°ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚
    ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’æ–°ã—ã„å†…å®¹ã«ç½®ãæ›ãˆã‚‹ã€‚
    """
    try:
        # ClaudeãŒ `new_str` ã§é€ã£ã¦ããŸå ´åˆã«ã‚‚å¯¾å¿œ
        if new_content is None and new_str is not None:
            new_content = new_str
        if new_content is None:
            raise ValueError("No code content provided.")
        
        full_path = safe_join(file_path)
        if not os.path.exists(full_path):
            raise FileNotFoundError(f"File '{file_path}' not found.")
        
        with open(full_path, "w", encoding="utf-8") as f:
            f.write(new_content)
        return f"Code in '{file_path}' updated successfully."
    except Exception as e:
        record_error(str(e))
        return str(e)

@mcp.tool()
def create_code(file_path: str, content) -> str:
    """
    æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚
    åŒåã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™ã€‚
    """
    try:
        full_path = safe_join(file_path)
        if os.path.exists(full_path):
            return f"Error: File '{file_path}' already exists."
        
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        
        if isinstance(content, dict):
            content = json.dumps(content, indent=2, ensure_ascii=False)
        
        with open(full_path, "w", encoding="utf-8") as f:
            f.write(content)
        return f"Code file '{file_path}' created successfully."
    except Exception as e:
        record_error(str(e))
        return str(e)

@mcp.tool()
def delete_code(file_path: str) -> str:
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚
    å‰Šé™¤å‰ã«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèªã™ã‚‹ã€‚
    """
    try:
        full_path = safe_join(file_path)
        if not os.path.exists(full_path):
            return f"Warning: File '{file_path}' does not exist."
        
        os.remove(full_path)
        return f"Deleted file: '{file_path}'"
    except Exception as e:
        record_error(str(e))
        return str(e)

@mcp.tool()
def move_code(from_path: str, to_path: str) -> str:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ¥ã®å ´æ‰€ã«ç§»å‹•ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚
    ç§»å‹•å…ˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è‡ªå‹•çš„ã«ä½œæˆã™ã‚‹ã€‚
    """
    try:
        from_full = safe_join(from_path)
        to_full = safe_join(to_path)
        
        if not os.path.exists(from_full):
            return f"Error: Source file '{from_path}' does not exist."
        
        os.makedirs(os.path.dirname(to_full), exist_ok=True)
        os.rename(from_full, to_full)
        return f"Moved '{from_path}' to '{to_path}'"
    except Exception as e:
        record_error(str(e))
        return str(e)

@mcp.tool()
def list_files_in_directory(directory_path: str) -> list[str]:
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä¸€è¦§è¡¨ç¤ºã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚
    """
    try:
        full_path = safe_join(directory_path)
        if not os.path.isdir(full_path):
            raise NotADirectoryError(f"'{directory_path}' is not a directory.")
        
        contents = os.listdir(full_path)
        return contents
    except Exception as e:
        record_error(str(e))
        return [str(e)]

@mcp.tool()
def investment_dashboard_policy() -> str:
    """
    æŠ•è³‡ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰åˆ†æãƒ»ç”Ÿæˆã®ãŸã‚ã®å°‚ç”¨ãƒãƒªã‚·ãƒ¼ã€‚
    ãƒãƒ¼ãƒ™ãƒ«æˆ¦ç•¥ã«åŸºã¥ãåˆ†æãƒ«ãƒ¼ãƒ«ã¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆãƒ•ãƒ­ãƒ¼ã‚’æä¾›ã€‚
    æŠ•è³‡é–¢é€£ã®ä½œæ¥­æ™‚ã«ã¯å¿…ãšã“ã®ãƒãƒªã‚·ãƒ¼ã‚’æœ€åˆã«èª­ã¿è¾¼ã‚€ã“ã¨ã€‚
    """
    return """
==============================
æŠ•è³‡ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆãƒãƒªã‚·ãƒ¼
==============================

ã€å‰ææ¡ä»¶ã€‘
æŠ•è³‡ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰é–¢é€£ã®ä½œæ¥­ã‚’é–‹å§‹ã™ã‚‹å‰ã«ã€å¿…ãšä»¥ä¸‹ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€ã“ã¨ï¼š
- investment://barbell_strategy (ãƒãƒ¼ãƒ™ãƒ«æˆ¦ç•¥ãƒ«ãƒ¼ãƒ«)
- investment://stock_mapping (éŠ˜æŸ„åˆ†é¡ãƒãƒƒãƒ”ãƒ³ã‚°)
- investment://fixed_assets (å›ºå®šè³‡ç”£ãƒ‡ãƒ¼ã‚¿: ç¾é‡‘ãƒ»æŠ•è³‡ä¿¡è¨—)

ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã€‘
investment_data/
â”œâ”€â”€ philosophy/        # æŠ•è³‡æ€æƒ³ãƒ»ãƒ«ãƒ¼ãƒ«å®šç¾©
â”œâ”€â”€ templates/         # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆTSXã‚³ãƒ¼ãƒ‰
â”œâ”€â”€ output/            # ç”Ÿæˆã•ã‚ŒãŸTSXãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
â””â”€â”€ samples/           # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ‡ãƒ¢ç”¨

ã€æ¨™æº–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€‘

â–  Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™
1. æŠ•è³‡ãƒ‡ãƒ¼ã‚¿CSVã‚’æŠ•è³‡ã‚·ã‚¹ãƒ†ãƒ ã«é…ç½®
2. list_files_in_directory("investment_data/samples") ã§ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª

â–  Phase 2: ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»çµ±åˆ
3. analyze_portfolio_csv ã‚’ä½¿ç”¨ã—ã¦CSVã‚’å‡¦ç†
4. 3ã¤ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å‚ç…§ã—ã¦å®Œå…¨ãªãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’æ§‹ç¯‰ï¼š
   - CSVãƒ‡ãƒ¼ã‚¿: è¨¼åˆ¸ãƒ‡ãƒ¼ã‚¿ã®è©•ä¾¡é¡ãƒ»æ ªæ•°ãƒ»æç›Šç‡
   - stock_mapping: éŠ˜æŸ„ã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆæ”»ã‚ãƒ»å®ˆã‚Šãƒ»ä¸­é–“ï¼‰
   - fixed_assets: ç¾é‡‘ãƒ»æŠ•è³‡ä¿¡è¨—ãƒ‡ãƒ¼ã‚¿
5. çµ±åˆã•ã‚ŒãŸãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ

â–  Phase 3: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆ
6. read_code("investment_data/templates/portfolio_dashboard.tsx") ã§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿
7. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã®ã¿ã‚’æ–°ã—ã„çµ±åˆåˆ†æçµæœã§ç½®æ›
8. create_code ã§æ–°ã—ã„ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ investment_data/output/ ã«ä¿å­˜

ã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆæ™‚ã®æ³¨æ„ç‚¹ã€‘
- æ—¢å­˜ã®TSXã‚³ãƒ¼ãƒ‰ã®æ§‹é€ ã¯ç¶­æŒã™ã‚‹
- ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ï¼ˆé…åˆ—ãƒ»ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã®ã¿ã‚’ç½®æ›
- ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã€å‹å®šç¾©ã¯å¤‰æ›´ã—ãªã„
- æ™‚ç³»åˆ—æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯å‰å›ãƒ‡ãƒ¼ã‚¿ã¨ã®å·®åˆ†ã‚’å¼·èª¿
- å›ºå®šè³‡ç”£ã‚’å¿…ãšå«ã‚ã¦åˆ†æ

ã€å‘½åè¦å‰‡ã€‘
- åˆ†æãƒ‡ãƒ¼ã‚¿: portfolio_analysis_YYYYMMDD_HHMMSS.json
- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: dashboard_YYYYMMDD_HHMMSS.tsx
- æ¯”è¼ƒãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: comparison_YYYYMMDD.tsx

ã€ç¦æ­¢äº‹é …ã€‘
- éŠ˜æŸ„åˆ†é¡ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆå¿…ãšãƒªã‚½ãƒ¼ã‚¹ã‚’å‚ç…§ï¼‰
- å›ºå®šè³‡ç”£ã®æœªçµ±åˆï¼ˆå¿…ãšfixed_assetsãƒªã‚½ãƒ¼ã‚¹ã‚’å‚ç…§ï¼‰
- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®å…¨é¢çš„ãªæ›¸ãæ›ãˆï¼ˆãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã®ã¿ç½®æ›ï¼‰
- ãƒãƒ¼ãƒ™ãƒ«æˆ¦ç•¥åŸå‰‡ã«åã™ã‚‹æ¨å¥¨
- å€‹äººæƒ…å ±ãƒ»æ©Ÿå¯†æƒ…å ±ã®å«æœ‰

==============================
"""

# --------------- æŠ•è³‡ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰é–¢é€£ãƒ„ãƒ¼ãƒ« ---------------- #

@mcp.tool()
def analyze_portfolio_csv(csv_file_path: str) -> str:
    """
    æŠ•è³‡CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦ä¿å­˜ã™ã‚‹ã€‚
    è¨¼åˆ¸ä¼šç¤¾CSVã®æ—¥æœ¬èªåˆ—åã«å¯¾å¿œã—ã€æ­£ç¢ºãªè©•ä¾¡é¡ãƒ»æ ªæ•°ãƒ»æç›Šç‡ã‚’å–å¾—ã€‚
    """
    try:
        full_csv_path = safe_join(csv_file_path)
        if not os.path.exists(full_csv_path):
            return f"Error: CSV file '{csv_file_path}' not found."
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•åˆ¤å®šï¼‰
        encodings = ['utf-8', 'shift_jis', 'iso-8859-1', 'cp932']
        csv_data = None
        
        for encoding in encodings:
            try:
                with open(full_csv_path, 'r', encoding=encoding) as f:
                    csv_reader = csv.DictReader(f)
                    csv_data = list(csv_reader)
                    columns = csv_reader.fieldnames
                break
            except UnicodeDecodeError:
                continue
        
        if csv_data is None:
            return "Error: Could not read CSV file with any supported encoding."
        
        # è¨¼åˆ¸ä¼šç¤¾CSVå½¢å¼ã®æ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        portfolio_holdings = {}
        
        for row in csv_data:
            # è¨¼åˆ¸ä¼šç¤¾CSVã®åˆ—åã«åŸºã¥ãæŠ½å‡º
            ticker = row.get('ãƒ†ã‚£ãƒƒã‚«ãƒ¼', '').strip().upper()
            
            # è©•ä¾¡é¡ï¼ˆå††ï¼‰ã®å–å¾—
            value_jpy_str = row.get('æ™‚ä¾¡è©•ä¾¡é¡[å††]', '0')
            try:
                value_jpy = float(str(value_jpy_str).replace(',', '').strip())
            except (ValueError, TypeError):
                value_jpy = 0
                
            # ä¿æœ‰æ ªæ•°ã®å–å¾—
            shares_str = row.get('ä¿æœ‰æ•°[æ ª]', '0')
            try:
                shares = float(str(shares_str).replace(',', '').strip())
            except (ValueError, TypeError):
                shares = 0
                
            # æç›Šç‡ã®å–å¾—
            gain_loss_str = row.get('æç›Šç‡[å††]', '0')
            try:
                gain_loss = float(str(gain_loss_str).replace(',', '').replace('%', '').strip())
            except (ValueError, TypeError):
                gain_loss = 0
                
            # è©•ä¾¡å˜ä¾¡ï¼ˆå††ï¼‰ã®å–å¾—
            price_jpy_str = row.get('è©•ä¾¡å˜ä¾¡[å††]', '0')
            try:
                price_jpy = float(str(price_jpy_str).replace(',', '').strip())
            except (ValueError, TypeError):
                price_jpy = 0
                
            # éŠ˜æŸ„åã®å–å¾—
            name = row.get('éŠ˜æŸ„', '').strip()
            
            if ticker and value_jpy > 0:
                portfolio_holdings[ticker] = {
                    'ticker': ticker,
                    'name': name,
                    'value_jpy': value_jpy,
                    'shares': shares,
                    'price_jpy': price_jpy,
                    'gain_loss_rate': gain_loss
                }
        
        # å‡¦ç†çµæœã‚’ä¿å­˜
        analysis_result = {
            "analysis_date": datetime.now().isoformat(),
            "source_csv": csv_file_path,
            "csv_holdings": portfolio_holdings,
            "csv_holdings_count": len(portfolio_holdings),
            "total_csv_value": sum(holding['value_jpy'] for holding in portfolio_holdings.values()),
            "raw_csv_sample": csv_data[:3]  # æœ€åˆã®3è¡Œã®ã‚µãƒ³ãƒ—ãƒ«
        }
        
        # åˆ†æçµæœã‚’ä¿å­˜
        analysis_file_path = f"investment_data/output/portfolio_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        save_json(analysis_file_path, analysis_result)
        
        total_value = analysis_result['total_csv_value']
        return f"""CSVå‡¦ç†å®Œäº†: {analysis_file_path}

ğŸ“Š æŠ½å‡ºçµæœ:
- éŠ˜æŸ„æ•°: {len(portfolio_holdings)}ä»¶
- ç·è©•ä¾¡é¡: Â¥{total_value:,.0f}
- ä¸»è¦éŠ˜æŸ„: {', '.join(list(portfolio_holdings.keys())[:5])}

âš ï¸ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:
1. 3ã¤ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å‚ç…§ã—ã¦ãã ã•ã„:
   - investment://barbell_strategy
   - investment://stock_mapping  
   - investment://fixed_assets
2. å›ºå®šè³‡ç”£ãƒ‡ãƒ¼ã‚¿ã¨çµ±åˆã—ã¦å®Œå…¨ãªãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’æ§‹ç¯‰
3. ãƒãƒ¼ãƒ™ãƒ«æˆ¦ç•¥åˆ†æã‚’å®Ÿè¡Œ"""
    
    except Exception as e:
        record_error(str(e))
        return f"CSVå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

# --------------- Resources ---------------- #
@mcp.resource("investment://barbell_strategy")
def barbell_strategy_rules() -> str:
    """
    ãƒãƒ¼ãƒ™ãƒ«æˆ¦ç•¥ã®æŠ•è³‡ãƒ«ãƒ¼ãƒ«ã¨åŸºæœ¬æ€æƒ³ã€‚
    investment_data/philosophy/barbell_strategy.mdãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã€‚
    """
    try:
        rules_path = safe_join("investment_data", "philosophy", "barbell_strategy.md")
        
        if os.path.exists(rules_path):
            with open(rules_path, "r", encoding="utf-8") as f:
                return f.read()
        else:
            return "ãƒãƒ¼ãƒ™ãƒ«æˆ¦ç•¥ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚philosophy/barbell_strategy.mdã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    except Exception as e:
        record_error(str(e))
        return f"[Error] ãƒãƒ¼ãƒ™ãƒ«æˆ¦ç•¥ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {str(e)}"

@mcp.resource("investment://fixed_assets")
def fixed_assets_data() -> str:
    """
    å›ºå®šè³‡ç”£ãƒ‡ãƒ¼ã‚¿ï¼ˆç¾é‡‘ãƒ»æŠ•è³‡ä¿¡è¨—ç­‰ï¼‰ã€‚
    investment_data/philosophy/fixed_assets.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã€‚
    """
    try:
        fixed_assets_path = safe_join("investment_data", "philosophy", "fixed_assets.json")
        
        if os.path.exists(fixed_assets_path):
            with open(fixed_assets_path, "r", encoding="utf-8") as f:
                return f.read()
        else:
            return "å›ºå®šè³‡ç”£ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚philosophy/fixed_assets.jsonã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    except Exception as e:
        record_error(str(e))
        return f"[Error] å›ºå®šè³‡ç”£ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—: {str(e)}"

@mcp.resource("investment://stock_mapping")
def stock_classification_mapping() -> str:
    """
    éŠ˜æŸ„åˆ†é¡ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ”»ã‚ãƒ»å®ˆã‚Šãƒ»ä¸­é–“ã®å®šç¾©ï¼‰ã€‚
    investment_data/philosophy/stock_mapping.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã€‚
    """
    try:
        mapping_path = safe_join("investment_data", "philosophy", "stock_mapping.json")
        
        if os.path.exists(mapping_path):
            with open(mapping_path, "r", encoding="utf-8") as f:
                return f.read()
        else:
            return "éŠ˜æŸ„åˆ†é¡ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚philosophy/stock_mapping.jsonã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    except Exception as e:
        record_error(str(e))
        return f"[Error] éŠ˜æŸ„åˆ†é¡ãƒãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿å¤±æ•—: {str(e)}"

# --------------- Entry Point ---------------- #
if __name__ == "__main__":
    mcp.run()